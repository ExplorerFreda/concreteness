{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet50_Updated.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "9pJf0euIbbKq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "576z96UveheO",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.multiprocessing as multiprocessing\n",
        "\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from annoy import AnnoyIndex\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "cuda = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vu_KqmU2DUld",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tags_directory = \"C:/ML/mirflickr25/meta/tags\"\n",
        "images_directory = \"C:/ML/mirflickr25\"\n",
        "tags_json_filename = \"C:/ML/mirflickr25/tags.json\"\n",
        "vectors_file = \"C:/ML/mirflickr25/vectors.pt\"\n",
        "annoy_index_file = \"C:/ML/mirflickr25/image_vectors.ann\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hznnObPPsEdf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_index_from_image_file(image_filename):\n",
        "  return int(image_filename[2:-4])\n",
        "\n",
        "\n",
        "def get_tags(tags_file):\n",
        "  with open(\"{}/{}\".format(tags_directory, tags_file), encoding=\"utf8\") as f:\n",
        "    return list(map(lambda x: x.strip(), f.readlines()))\n",
        "\n",
        "  \n",
        "def get_index_from_tags_file(tags_file):\n",
        "  return int(tags_file[4:-4])\n",
        "\n",
        "\n",
        "def is_image_file(file):\n",
        "  return file[-4:] == \".jpg\"\n",
        "\n",
        "\n",
        "def build_tags_json(tag_files, tags_json_filename):\n",
        "  image_tags = {}\n",
        "\n",
        "  for i, tags_file in enumerate(tag_files):\n",
        "    image_tags[get_index_from_tags_file(tags_file)] = get_tags(tags_file)\n",
        "  \n",
        "  with open(tags_json_filename, \"w\", encoding=\"utf8\") as tags_json_file:\n",
        "    json.dump(image_tags, tags_json_file)\n",
        "        \n",
        "  return image_tags\n",
        "\n",
        "\n",
        "def load_tags_json(tags_json_filename):\n",
        "  with open(tags_json_filename, \"r\") as tags_json_file:\n",
        "    image_tags = json.load(tags_json_file)\n",
        "    return image_tags\n",
        "\n",
        "\n",
        "def get_tag_scores(image_tags):\n",
        "  tag_scores = {}\n",
        "  for tags in image_tags.values():\n",
        "    for tag in tags:\n",
        "      tag = tag.lower()\n",
        "      tag_scores[tag] = tag_scores.get(tag, 0) + 1\n",
        "\n",
        "  return tag_scores\n",
        "\n",
        "\n",
        "def get_filtered_tags(image_tags):\n",
        "  tag_scores = get_tag_scores(image_tags)\n",
        "  \n",
        "  # Will keep only the tags that have at least 100 occurrences\n",
        "  filtered_tags = {}\n",
        "  for image, tags in image_tags.items():\n",
        "    filtered_image_tags = []\n",
        "    for tag in tags:\n",
        "      if tag_scores.get(tag, 0) >= 100:\n",
        "        filtered_image_tags.append(tag)\n",
        "      \n",
        "    if filtered_image_tags:\n",
        "      filtered_tags[int(image)] = filtered_image_tags\n",
        "      \n",
        "  return filtered_tags\n",
        "\n",
        "        \n",
        "def get_image_score(image_tags, image):\n",
        "  image_index = get_index_from_image_file(image)\n",
        "  return len(image_tags.get(image_index, []))\n",
        "\n",
        "\n",
        "def get_filtered_images(images_directory, tags_directory, min_score=3):\n",
        "  image_tags = build_tags_json(list_tag_files(tags_directory), tags_json_filename)\n",
        "  filtered_tags = get_filtered_tags(image_tags)\n",
        "  images = list_image_files(images_directory)    \n",
        "  return [img for img in images if get_image_score(filtered_tags, img) >= min_score]\n",
        "\n",
        "\n",
        "def list_image_files(images_directory):\n",
        "  images = sorted([f for f in os.listdir(images_directory) if is_image_file(f)],\n",
        "                   key=lambda f: get_index_from_image_file(f))\n",
        "  return images\n",
        "\n",
        "\n",
        "def show_image(filtered_images, image_index):\n",
        "  image_filepath = \"{}/{}\".format(images_directory,\n",
        "                                  filtered_images[image_index])\n",
        "  imshow(np.asarray(Image.open(image_filepath)))\n",
        "\n",
        "\n",
        "def list_tag_files(tags_directory):\n",
        "  tag_files = sorted(os.listdir(tags_directory),\n",
        "                     key=lambda f: get_index_from_tags_file(f))\n",
        "  return tag_files\n",
        "\n",
        "\n",
        "def get_model():\n",
        "  resnet = models.resnet50(pretrained=True)\n",
        "\n",
        "  for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "   \n",
        "  resnet.eval()\n",
        "\n",
        "  if cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    resnet.to(device)\n",
        "    \n",
        "  return resnet\n",
        "\n",
        "\n",
        "def img2vec(resnet, image_tensors):\n",
        "    last_layer = resnet._modules.get(\"avgpool\")\n",
        "    \n",
        "    if cuda:\n",
        "        image_tensors = image_tensors.cuda()\n",
        "    \n",
        "    embedding = torch.zeros(image_tensors.shape[0], 2048, 1, 1)\n",
        "    \n",
        "    def copy_output(m, i, o):\n",
        "        embedding.copy_(o.data)\n",
        "    \n",
        "    h = last_layer.register_forward_hook(copy_output)\n",
        "    resnet(image_tensors)\n",
        "    h.remove()\n",
        "\n",
        "    return embedding\n",
        "\n",
        "\n",
        "# These are the expected values of this pre-trained model.\n",
        "# See https://pytorch.org/docs/stable/torchvision/models.html#torchvision-models\n",
        "input_image_size = (224, 224)\n",
        "expected_mean = [0.485, 0.456, 0.406]\n",
        "expected_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "scaler = transforms.Resize(input_image_size)\n",
        "normalize = transforms.Normalize(mean=expected_mean, std=expected_std)\n",
        "to_tensor = transforms.ToTensor()\n",
        "\n",
        "\n",
        "def get_tensor_for_image(file_path):\n",
        "  img = Image.open(file_path)\n",
        "  variable = Variable(normalize(to_tensor(scaler(img))))\n",
        "  return variable\n",
        "\n",
        "\n",
        "class MirflickrImagesDataset(Dataset):\n",
        "  def __init__(self, images_directory, image_files):\n",
        "    self.images_directory = images_directory\n",
        "    self.image_files = image_files\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.image_files)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    return get_tensor_for_image(self.get_image_path(self.image_files[idx]))\n",
        "  \n",
        "  def get_image_path(self, file):\n",
        "    return \"{}/{}\".format(self.images_directory, file)\n",
        "\n",
        "\n",
        "def _build_image_vectors(dataset, resnet, images, batch_size=64, num_workers=4):\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
        "\n",
        "  img_vectors = torch.zeros(len(images), 2048, 1, 1)\n",
        "\n",
        "  for batch_index, batch in enumerate(dataloader):\n",
        "    batch_start = batch_index * batch_size\n",
        "    batch_end = batch_start + batch_size\n",
        "    \n",
        "    # Pad the last batch if it's smaller than batch_size\n",
        "    if batch.shape[0] != batch_size:\n",
        "      new_batch = torch.zeros(batch_size, batch.shape[1], batch.shape[2],\n",
        "                              batch.shape[3])\n",
        "      new_batch[:batch.shape[0]] = batch\n",
        "      img_vectors[batch_start:batch_end] = img2vec(resnet, new_batch)[:batch.shape[0]]\n",
        "      continue\n",
        "    \n",
        "    img_vectors[batch_start:batch_end] = img2vec(resnet, batch)\n",
        "    print(\"computed batch {}\".format(batch_index))\n",
        "    \n",
        "  return img_vectors\n",
        "\n",
        "\n",
        "def build_and_save_image_vectors():\n",
        "  filtered_images = get_filtered_images(images_directory, tags_directory)\n",
        "\n",
        "  dataset = MirflickrImagesDataset(images_directory, filtered_images)\n",
        "  resnet = get_model()\n",
        "  img_vectors = _build_image_vectors(dataset, resnet, filtered_images)\n",
        "  torch.save(img_vectors, vectors_file)\n",
        "  return img_vectors\n",
        "\n",
        "\n",
        "def build_annoy_index(img_vectors):\n",
        "  annoy_index = AnnoyIndex(2048)\n",
        "  for i in range(len(img_vectors)):\n",
        "    annoy_index.add_item(i, img_vectors[i])\n",
        "  \n",
        "  annoy_index.build(10)\n",
        "  return annoy_index\n",
        "\n",
        "\n",
        "def load_annoy_index(file):\n",
        "  annoy_index = AnnoyIndex(2048)\n",
        "  annoy_index.load(file)\n",
        "  return annoy_index\n",
        "\n",
        "\n",
        "def main():\n",
        "  img_vectors = build_and_save_image_vectors()\n",
        "  #img_vectors = torch.load(vectors_file)\n",
        "\n",
        "  annoy_index = build_annoy_index(img_vectors)\n",
        "  annoy_index.save(annoy_index_file)\n",
        "  #annoy_index = load_annoy_index(annoy_index_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XOJazaDuDUlh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_images_by_tag(filtered_tags):\n",
        "  images_by_tag = {}\n",
        "  for image, tags in filtered_tags.items():\n",
        "    for tag in tags:\n",
        "      images_by_tag.setdefault(tag, set()).add(image)\n",
        "\n",
        "  return images_by_tag    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VoEXNQyTDUlj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_filtered_image_to_index(filtered_images):\n",
        "  filtered_image_to_index = {}\n",
        "  for i, image in enumerate(filtered_images):\n",
        "    filtered_image_to_index[get_index_from_image_file(image)] = i\n",
        "  return filtered_image_to_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ier1DQJiDUlk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_concreteness(images_by_tag, filtered_image_to_index, word, annoy_index, n, k=5):\n",
        "  mni = 0.0\n",
        "  associated_images = images_by_tag[word]\n",
        "\n",
        "  for image in associated_images:\n",
        "    if image not in filtered_image_to_index:\n",
        "        continue\n",
        "\n",
        "    neighbors = set(annoy_index.get_nns_by_item(filtered_image_to_index[image], k))\n",
        "    mni += 1.0 * (len(associated_images.intersection(neighbors)))\n",
        "  \n",
        "  mni = mni / len(associated_images)  \n",
        "  denominator = (1.0 * k * len(associated_images)) / n\n",
        "  return mni / denominator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-KkeOGODUlm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Since these files have already been computed, we'll just load them from disk\n",
        "img_vectors = torch.load(vectors_file)\n",
        "annoy_index = load_annoy_index(annoy_index_file)\n",
        "\n",
        "image_tags = load_tags_json(tags_json_filename)\n",
        "filtered_tags = get_filtered_tags(image_tags)\n",
        "images_by_tag = get_images_by_tag(filtered_tags)\n",
        "n = len(filtered_tags)\n",
        "\n",
        "filtered_images = get_filtered_images(images_directory, tags_directory)\n",
        "filtered_image_to_index = get_filtered_image_to_index(filtered_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1J7fvnfrDUlo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concreteness = {}\n",
        "for word in images_by_tag:\n",
        "  concreteness[word] = get_concreteness(images_by_tag, filtered_image_to_index, word,\n",
        "                                        annoy_index, n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gxMXwaX6DUlq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sorted_concreteness = sorted(concreteness.items(), key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-HWFxTicDUlt",
        "colab_type": "code",
        "outputId": "d6e25ab6-2360-4bc0-b923-51ce89e6f063",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(sorted_concreteness)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "208"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}